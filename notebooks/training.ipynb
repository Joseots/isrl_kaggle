{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "\n",
    "from scripts.data_generator import DataGenerator, LoadData\n",
    "from scripts.config import train_set, index_map, LANDMARKS, DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with parquet files\n",
    "\n",
    "data_size = len(train_set)\n",
    "list_IDs = np.arange(data_size)\n",
    "np.random.shuffle(list_IDs)\n",
    "val_start = int(data_size*.95)\n",
    "batch_size = 128\n",
    "\n",
    "# Generators\n",
    "train_gen = DataGenerator(list_IDs[:val_start], train_set,\n",
    "                          index_map, batch_size=batch_size)\n",
    "val_gen = DataGenerator(list_IDs[val_start:], train_set,\n",
    "                        index_map, batch_size=batch_size)\n",
    "\n",
    "input_shape = (160, 85, 3)\n",
    "model = keras.applications.EfficientNetB0(\n",
    "    weights=None,\n",
    "    input_shape=input_shape,\n",
    "    classes=250\n",
    ")\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='CategoricalCrossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# checkpoint\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('best_model.h5',\n",
    "                                                monitor='accuracy', mode='max',\n",
    "                                                verbose=1, save_best_only=True)\n",
    "es = keras.callbacks.EarlyStopping(monitor='loss', mode='min',\n",
    "                                      verbose=1, patience=200)\n",
    "callbacks_list = [es, checkpoint]\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit(x=train_gen,\n",
    "          validation_data=val_gen,\n",
    "          epochs=20,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset\n",
    "\n",
    "data_size = len(train_set)\n",
    "input_shape = (60, 85)\n",
    "X = np.empty((data_size, input_shape[0], input_shape[1], 3))\n",
    "y = np.empty((data_size, 250), dtype=int)\n",
    "dataloader = LoadData()\n",
    "\n",
    "for index, row in train_set.iterrows():\n",
    "    data = dataloader.load_relevant_data_subset(DATAPATH + row.path)\n",
    "    data = np.nan_to_num(data[:, LANDMARKS, :], 0)\n",
    "    data = tf.image.resize(data, size=input_shape, method='nearest')\n",
    "    X[index, ] = data.numpy()\n",
    "    y[index, ] = keras.utils.to_categorical(index_map[row.sign], num_classes=250)\n",
    "\n",
    "print(f'Data size: {len(X)}\\nX shape: {X[0].shape}\\ny shape: {y[0].shape}')\n",
    "\n",
    "\n",
    "np.save('data/X_data', X)\n",
    "np.save('data/y_data', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSequence(keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        return self.X[indexes], self.y[indexes]\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle is True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 5.3502 - accuracy: 0.0101\n",
      "Epoch 1: val_loss improved from inf to 5.17368, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 213s 66ms/step - loss: 5.3502 - accuracy: 0.0101 - val_loss: 5.1737 - val_accuracy: 0.0128\n",
      "Epoch 2/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 4.3938 - accuracy: 0.0663\n",
      "Epoch 2: val_loss improved from 5.17368 to 4.04500, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 4.3938 - accuracy: 0.0663 - val_loss: 4.0450 - val_accuracy: 0.1084\n",
      "Epoch 3/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 3.4313 - accuracy: 0.2057\n",
      "Epoch 3: val_loss improved from 4.04500 to 2.89428, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 184s 65ms/step - loss: 3.4313 - accuracy: 0.2057 - val_loss: 2.8943 - val_accuracy: 0.3087\n",
      "Epoch 4/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 2.8260 - accuracy: 0.3205\n",
      "Epoch 4: val_loss improved from 2.89428 to 2.61501, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 188s 67ms/step - loss: 2.8260 - accuracy: 0.3205 - val_loss: 2.6150 - val_accuracy: 0.3739\n",
      "Epoch 5/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 2.4346 - accuracy: 0.4025\n",
      "Epoch 5: val_loss improved from 2.61501 to 2.14510, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 188s 67ms/step - loss: 2.4346 - accuracy: 0.4025 - val_loss: 2.1451 - val_accuracy: 0.4677\n",
      "Epoch 6/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 2.1445 - accuracy: 0.4657\n",
      "Epoch 6: val_loss improved from 2.14510 to 1.96668, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 2.1445 - accuracy: 0.4657 - val_loss: 1.9667 - val_accuracy: 0.5106\n",
      "Epoch 7/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 1.9464 - accuracy: 0.5108\n",
      "Epoch 7: val_loss improved from 1.96668 to 1.84472, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 1.9464 - accuracy: 0.5108 - val_loss: 1.8447 - val_accuracy: 0.5419\n",
      "Epoch 8/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 1.7946 - accuracy: 0.5432\n",
      "Epoch 8: val_loss improved from 1.84472 to 1.74979, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 1.7946 - accuracy: 0.5432 - val_loss: 1.7498 - val_accuracy: 0.5576\n",
      "Epoch 9/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 1.5848 - accuracy: 0.5923\n",
      "Epoch 9: val_loss improved from 1.74979 to 1.61093, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 206s 73ms/step - loss: 1.5848 - accuracy: 0.5923 - val_loss: 1.6109 - val_accuracy: 0.5940\n",
      "Epoch 10/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 1.4525 - accuracy: 0.6218\n",
      "Epoch 10: val_loss improved from 1.61093 to 1.59406, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 421s 150ms/step - loss: 1.4525 - accuracy: 0.6218 - val_loss: 1.5941 - val_accuracy: 0.5982\n",
      "Epoch 11/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 1.3384 - accuracy: 0.6468\n",
      "Epoch 11: val_loss improved from 1.59406 to 1.52441, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 193s 69ms/step - loss: 1.3384 - accuracy: 0.6468 - val_loss: 1.5244 - val_accuracy: 0.6103\n",
      "Epoch 12/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 1.2412 - accuracy: 0.6722\n",
      "Epoch 12: val_loss improved from 1.52441 to 1.49458, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 186s 66ms/step - loss: 1.2412 - accuracy: 0.6722 - val_loss: 1.4946 - val_accuracy: 0.6261\n",
      "Epoch 13/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 1.1860 - accuracy: 0.6862\n",
      "Epoch 13: val_loss improved from 1.49458 to 1.40636, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 1.1860 - accuracy: 0.6862 - val_loss: 1.4064 - val_accuracy: 0.6520\n",
      "Epoch 14/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 1.0637 - accuracy: 0.7157\n",
      "Epoch 14: val_loss improved from 1.40636 to 1.33619, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 1.0637 - accuracy: 0.7157 - val_loss: 1.3362 - val_accuracy: 0.6764\n",
      "Epoch 15/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.9942 - accuracy: 0.7319\n",
      "Epoch 15: val_loss did not improve from 1.33619\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.9942 - accuracy: 0.7319 - val_loss: 1.3586 - val_accuracy: 0.6671\n",
      "Epoch 16/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.9005 - accuracy: 0.7562\n",
      "Epoch 16: val_loss improved from 1.33619 to 1.31194, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 0.9005 - accuracy: 0.7562 - val_loss: 1.3119 - val_accuracy: 0.6886\n",
      "Epoch 17/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.7695\n",
      "Epoch 17: val_loss did not improve from 1.31194\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 0.8386 - accuracy: 0.7695 - val_loss: 1.3150 - val_accuracy: 0.6824\n",
      "Epoch 18/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.7726 - accuracy: 0.7859\n",
      "Epoch 18: val_loss improved from 1.31194 to 1.30981, saving model to best_model_pool.h5\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.7726 - accuracy: 0.7859 - val_loss: 1.3098 - val_accuracy: 0.6894\n",
      "Epoch 19/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.7091 - accuracy: 0.7994\n",
      "Epoch 19: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.7091 - accuracy: 0.7994 - val_loss: 1.3307 - val_accuracy: 0.6947\n",
      "Epoch 20/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.6454 - accuracy: 0.8155\n",
      "Epoch 20: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 0.6454 - accuracy: 0.8155 - val_loss: 1.3696 - val_accuracy: 0.6947\n",
      "Epoch 21/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.8259\n",
      "Epoch 21: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.6002 - accuracy: 0.8259 - val_loss: 1.4018 - val_accuracy: 0.7000\n",
      "Epoch 22/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.8394\n",
      "Epoch 22: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.5534 - accuracy: 0.8394 - val_loss: 1.3449 - val_accuracy: 0.7017\n",
      "Epoch 23/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.8494\n",
      "Epoch 23: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.5108 - accuracy: 0.8494 - val_loss: 1.4065 - val_accuracy: 0.7022\n",
      "Epoch 24/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8582\n",
      "Epoch 24: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.4744 - accuracy: 0.8582 - val_loss: 1.4233 - val_accuracy: 0.7030\n",
      "Epoch 25/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.8676\n",
      "Epoch 25: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 184s 65ms/step - loss: 0.4397 - accuracy: 0.8676 - val_loss: 1.4554 - val_accuracy: 0.7045\n",
      "Epoch 26/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.4134 - accuracy: 0.8750\n",
      "Epoch 26: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.4134 - accuracy: 0.8750 - val_loss: 1.4356 - val_accuracy: 0.7113\n",
      "Epoch 27/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8826\n",
      "Epoch 27: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 184s 66ms/step - loss: 0.3817 - accuracy: 0.8826 - val_loss: 1.4839 - val_accuracy: 0.7026\n",
      "Epoch 28/40\n",
      "2804/2804 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8873\n",
      "Epoch 28: val_loss did not improve from 1.30981\n",
      "2804/2804 [==============================] - 183s 65ms/step - loss: 0.3656 - accuracy: 0.8873 - val_loss: 1.4553 - val_accuracy: 0.7158\n",
      "Epoch 28: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1b687c99f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with custom dataset\n",
    "X = np.load('data/X_data.npy')\n",
    "y = np.load('data/y_data.npy')\n",
    "\n",
    "model = keras.applications.EfficientNetB1(\n",
    "    weights=None,\n",
    "    input_shape=X.shape[1:],\n",
    "    classes=y.shape[1]\n",
    ")\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='CategoricalCrossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training callbacks\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'best_model_pool.h5', monitor='val_loss', mode='min',\n",
    "    verbose=1, save_best_only=True\n",
    "    )\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=10\n",
    "    )\n",
    "cb_list = [es, checkpoint]\n",
    "\n",
    "# Create generators\n",
    "data_size = len(X)\n",
    "val_start = int(data_size*.95)\n",
    "batch_size = 32\n",
    "\n",
    "train_gen = DataSequence(X[:val_start], y[:val_start], batch_size=batch_size)\n",
    "val_gen = DataSequence(X[val_start:], y[val_start:], batch_size=batch_size)\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit(x=train_gen,\n",
    "          validation_data=val_gen,\n",
    "          epochs=40,\n",
    "          callbacks=cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(tf.keras.layers.Layer):\n",
    "    def __init__(self, point_landmarks=LANDMARKS, shape=(60,85), **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.point_landmarks = point_landmarks\n",
    "        self.shape = shape\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.gather(inputs, LANDMARKS, axis=1)\n",
    "        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
    "        x  = tf.image.resize(x, size=(self.shape[0],85), method='nearest')\n",
    "        return tf.reshape(x, (1,self.shape[0],self.shape[1],3))\n",
    "    \n",
    "class InferenceModel(tf.Module):\n",
    "    def __init__(self, islr_model, shape=(60,85)):\n",
    "        super(InferenceModel, self).__init__()\n",
    "        self.islr_model = islr_model\n",
    "        self.shape = shape\n",
    "        self.prep_inputs = Preprocess(shape=self.shape)\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        x = self.prep_inputs(tf.cast(inputs, dtype=tf.float32))\n",
    "        outputs = self.islr_model(x) \n",
    "        return {'outputs': outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as preprocess_1_layer_call_fn, preprocess_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 118). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7jbpyh2p/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7jbpyh2p/assets\n"
     ]
    }
   ],
   "source": [
    "islr_model = keras.models.load_model('best_model_pool.h5')\n",
    "inference_model = InferenceModel(islr_model, shape=X.shape[1:3])\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(inference_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
